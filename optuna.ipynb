{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "db32f588-a605-429e-b8de-4c0167c21f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import optuna\n",
    "from lightgbm import LGBMClassifier\n",
    "from optuna import Trial\n",
    "from optuna.samplers import TPESampler\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "from lightgbm import plot_importance\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "effc0239-a3b1-42ad-abbe-f5713a127389",
   "metadata": {},
   "outputs": [],
   "source": [
    "from process import input_data, modeling, preprocess\n",
    "data = pd.read_csv('storage/churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a89521fd-5946-4c48-8ba8-15255cf1531f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data_load:\n",
    "    def __init__(self, path):\n",
    "        self.path = path #데이터 위치 경로 입력\n",
    "    \n",
    "    \n",
    "    # 데이터 불러오기\n",
    "    def read_data(self):\n",
    "        df = pd.read_csv(self.path) \n",
    "        var_list = df.columns.tolist() #전체 변수리스트 추출\n",
    "        num_var = df.select_dtypes(include='float').columns.tolist() + df.select_dtypes(include='int').columns.tolist() #수치형 변수 추출\n",
    "        obj_var = [x for x in df.columns if x not in num_var] #문자형 변수 추출\n",
    "        return df, var_list, num_var, obj_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "454f9627-35f3-45f1-9923-e7700c2935ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#전처리 class\n",
    "class Preprocessing:\n",
    "    def __init__(self, data, var_list, num_var, obj_var, target, anomaly_per, na, outlier, tree_model):\n",
    "        self.df = data                                     # 데이터\n",
    "        self.target = target                               # 타겟 변수\n",
    "        self.var_list = var_list                           # 전체 변수 리스트\n",
    "        self.num_var = num_var                             # 수치형 변수 리스트\n",
    "        self.obj_var = obj_var                             # 문자형 변수 리스트\n",
    "        self._anomaly_ratio = int(anomaly_per)             # 지정 이상치 범위\n",
    "        self._anomaly_percentage = int(anomaly_per) / 100\n",
    "        \n",
    "        self.na_pre = na                                   #결측치 처리 여부\n",
    "        self.outlier_pre = outlier                         #이상치 처리 여부\n",
    "        self.stand_pre = tree_model                        #정규화 처리 여부 => 트리 모델의 경우 생략 가능\n",
    "        \n",
    "        if self.na_pre:\n",
    "            self.df = self.na_preprocess(self.df, self._anomaly_ratio)\n",
    "        \n",
    "        if self.outlier_pre:\n",
    "            self.df = self.outlier_preprocess(self.df, self.num_var)\n",
    "        \n",
    "        # 타겟 변수 num_var 일 때 분리(obj_var일 경우 라벨 인코딩해야 하기 때문에 제외하지 않음)\n",
    "        if self.target in self.num_var:\n",
    "            self.num_var.remove(self.target)\n",
    "        \n",
    "        # 표준화\n",
    "        if self.stand_pre is False:\n",
    "            self.df = self.standardize(self.df, self.num_var)\n",
    "        \n",
    "        # 라벨 인코딩\n",
    "        self.df = self.label_encoder(self.df, self.obj_var)\n",
    "        \n",
    "        if self.target in self.obj_var:\n",
    "            self.obj_var.remove(self.target)\n",
    "    \n",
    "    # 결측치 확인 및 처리\n",
    "    def na_preprocess(self, df, anomaly_per):\n",
    "        \n",
    "        #Column별 결측치 n% 이상 있을 경우 제외\n",
    "        remove_v1 = round(df.isnull().sum() / len(df)*100, 2)\n",
    "        tmp_df = df[remove_v1[remove_v1 < anomaly_per].index]\n",
    "        \n",
    "        #Row별 결측치 n% 이상 있을 경우 제외\n",
    "        idx1 = len(tmp_df.columns) * 0.7\n",
    "        print('결측치 처리')\n",
    "        return tmp_df.dropna(thresh=idx1, axis=0)\n",
    "        \n",
    "        \n",
    "    # 이상치 제거\n",
    "    def outlier_preprocess(self, df, num_var):\n",
    "        num_data = df.loc[:, num_var]\n",
    "        \n",
    "        #IQR 기준\n",
    "        quartile_1 = num_data.quantile(0.25)\n",
    "        quartile_3 = num_data.quantile(0.75)\n",
    "        IQR = quartile_3 - quartile_1\n",
    "\n",
    "        condition = (num_data < (quartile_1 - 1.5 * IQR)) | (num_data > (quartile_3 + 1.5 * IQR)) # 1.5 수치가 바뀌어야함\n",
    "        condition = condition.any(axis=1)\n",
    "        search_df = df[condition]\n",
    "        print('이상치 처리')\n",
    "        return df.drop(search_df.index, axis=0)\n",
    "        \n",
    "    \n",
    "        \n",
    "    #트리 모델이 아닐 경우 표준화 진행, 본 사업 '고객 이탈 모형'에서는 진행 x\n",
    "    def standardize(self, df, num_var):\n",
    "        num_data = df.loc[:, num_var]\n",
    "        non_num_data = df.drop(set(num_var), axis=1)\n",
    "        \n",
    "        #표준화\n",
    "        std_scaler = StandardScaler()\n",
    "        fitted = std_scaler.fit(num_data)\n",
    "        output = std_scaler.transform(num_data)\n",
    "        num_data = pd.DataFrame(output, columns = num_data.columns, index=list(num_data.index.values))\n",
    "        \n",
    "        tmp_df = pd.concat([non_num_data, num_data], axis=1)\n",
    "        print('표준화')\n",
    "        return tmp_df\n",
    "        \n",
    "    \n",
    "    #문자형 변수를 수치형으로 변환\n",
    "    def label_encoder(self, df, obj_var):\n",
    "        obj_data = df.loc[:, obj_var]\n",
    "        non_obj_data = df.drop(set(obj_var), axis=1)\n",
    "\n",
    "        #인코딩\n",
    "        obj_output = pd.DataFrame()\n",
    "        for obj_col in obj_var:\n",
    "            lb_encoder = LabelEncoder()\n",
    "            output = lb_encoder.fit_transform(obj_data.loc[:, obj_col])\n",
    "            output = pd.DataFrame(output, index = list(obj_data.index.values))\n",
    "            obj_output = pd.concat([obj_output, output], axis=1)\n",
    "        obj_output.columns = obj_var\n",
    "        tmp_df = pd.concat([obj_output, non_obj_data], axis=1)\n",
    "        print('수치형 변환')\n",
    "        return tmp_df\n",
    "    \n",
    "    def get_df(self):\n",
    "        return self.df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f414240e-aaae-4bb9-afb0-1abe32ae3261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "표준화\n",
      "수치형 변환\n"
     ]
    }
   ],
   "source": [
    "data, var_list, num_var, obj_var = Data_load('storage/churn.csv').read_data()\n",
    "pp = Preprocessing(data, var_list, num_var, obj_var, target='churn', anomaly_per=10, na=False, outlier=False, tree_model=False)\n",
    "df = pp.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ddb72011-edeb-4b00-9a7d-f65711475991",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['churn'], axis=1)\n",
    "y = df['churn']\n",
    "X_test = X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a7a6799d-44e8-47a7-93ec-c993d70715bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial: Trial) -> float:\n",
    "    params_lgb = {\n",
    "        \"random_state\": 42,\n",
    "        \"verbosity\": -1,\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"n_estimators\": 10000,\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": \"auc\",\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-8, 3e-5),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-8, 9e-2),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 1, 20),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.4, 1.0),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.3, 1.0),\n",
    "        \"subsample_freq\": trial.suggest_int(\"subsample_freq\", 1, 10),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n",
    "        \"max_bin\": trial.suggest_int(\"max_bin\", 200, 500),\n",
    "    }\n",
    "    \n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "    model = LGBMClassifier(**params_lgb)\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "        #early_stopping_rounds=100,\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    lgb_pred = model.predict_proba(X_valid)[:,1]\n",
    "    lgb_score = roc_auc_score(y_valid, lgb_pred)\n",
    "    \n",
    "    return lgb_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "617804b3-18c3-4794-a093-54becff9ed27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-20 16:10:34,405]\u001b[0m A new study created in memory with name: lgbm_parameter_opt\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "sampler = TPESampler(seed=42)\n",
    "study = optuna.create_study(\n",
    "    study_name=\"lgbm_parameter_opt\",\n",
    "    direction=\"maximize\",\n",
    "    sampler=sampler,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6d15ec30-65fe-40bf-8054-33277a0511f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.9118336483931948\n",
      "Best trial: {'reg_alpha': 1.7560829253683595e-07, 'reg_lambda': 0.07339153040632079, 'max_depth': 15, 'num_leaves': 187, 'colsample_bytree': 0.8627622080115674, 'subsample': 0.35183125621386324, 'subsample_freq': 4, 'min_child_samples': 16, 'max_bin': 459}\n"
     ]
    }
   ],
   "source": [
    "#study.optimize(objective, n_trials=10)\n",
    "print(\"Best Score:\", study.best_value)\n",
    "print(\"Best trial:\", study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a04e3482-f340-4797-b135-986b44cb5bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df.drop(['churn'], axis=1).values\n",
    "y_train = df['churn'].values\n",
    "y_train = y_train.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "877ee658-956c-47fd-8587-b2addb989afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a12e7ade-05ba-4b35-a38b-bcc00f95cd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Objective(trial):\n",
    "    mask_type = trial.suggest_categorical(\"mask_type\", [\"entmax\", \"sparsemax\"])\n",
    "    n_da = trial.suggest_int(\"n_da\", 56, 64, step=4)\n",
    "    n_steps = trial.suggest_int(\"n_steps\", 1, 3, step=1)\n",
    "    gamma = trial.suggest_float(\"gamma\", 1., 1.4, step=0.2)\n",
    "    n_shared = trial.suggest_int(\"n_shared\", 1, 3)\n",
    "    lambda_sparse = trial.suggest_float(\"lambda_sparse\", 1e-6, 1e-3, log=True)\n",
    "    tabnet_params = dict(n_d=n_da, n_a=n_da, n_steps=n_steps, gamma=gamma,\n",
    "                     lambda_sparse=lambda_sparse, optimizer_fn=torch.optim.Adam,\n",
    "                     optimizer_params=dict(lr=2e-2, weight_decay=1e-5),\n",
    "                     mask_type=mask_type, n_shared=n_shared,\n",
    "                     scheduler_params=dict(mode=\"min\",\n",
    "                                           patience=trial.suggest_int(\"patienceScheduler\",low=3,high=10), # changing sheduler patience to be lower than early stopping patience \n",
    "                                           min_lr=1e-5,\n",
    "                                           factor=0.5,),\n",
    "                     scheduler_fn=torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "                     verbose=0,\n",
    "                     ) #early stopping\n",
    "    \n",
    "    folds=StratifiedKFold(n_splits=2, shuffle=True, random_state=42)\n",
    "    \n",
    "    CV_score_array    =[]\n",
    "    \n",
    "    for n_fold, (train_index, val_index) in enumerate(folds.split(X_train, y_train)):\n",
    "\n",
    "        train_x, val_x = X_train[train_index], X_train[val_index]\n",
    "        train_y, val_y = y_train[train_index], y_train[val_index]\n",
    "        \n",
    "        classifier = TabNetClassifier(**tabnet_params)\n",
    "        classifier.fit(X_train=train_x, y_train=train_y,\n",
    "                  eval_set=[(val_x, val_y)],\n",
    "                  patience=trial.suggest_int(\"patience\",low=15,high=30), max_epochs=trial.suggest_int('epochs', 1, 100),\n",
    "                  eval_metric=['auc'])\n",
    "        CV_score_array.append(classifier.best_cost)\n",
    "    avg = np.mean(CV_score_array)\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4b6694f1-0288-4d4c-ba2c-4564cf113949",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-20 16:22:59,559]\u001b[0m A new study created in memory with name: TabNet optimization\u001b[0m\n",
      "\u001b[33m[W 2023-01-20 16:22:59,564]\u001b[0m Trial 0 failed with parameters: {'mask_type': 'entmax', 'n_da': 64, 'n_steps': 3, 'gamma': 1.2, 'n_shared': 3, 'lambda_sparse': 0.00016406955797675018, 'patienceScheduler': 3} because of the following error: NameError(\"name 'KFold' is not defined\").\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\dpapf\\anaconda3\\envs\\demand\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\dpapf\\AppData\\Local\\Temp\\ipykernel_1376\\1448854290.py\", line 20, in Objective\n",
      "    kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
      "NameError: name 'KFold' is not defined\n",
      "\u001b[33m[W 2023-01-20 16:22:59,565]\u001b[0m Trial 0 failed with value None.\u001b[0m\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'KFold' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [45], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m, study_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTabNet optimization\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mObjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#5 hours\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\demand\\lib\\site-packages\\optuna\\study\\study.py:425\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    323\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    330\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    332\u001b[0m     \u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    333\u001b[0m \n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    422\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    423\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 425\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    427\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    429\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    430\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    431\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    434\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\demand\\lib\\site-packages\\optuna\\study\\_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 66\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\demand\\lib\\site-packages\\optuna\\study\\_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 163\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\demand\\lib\\site-packages\\optuna\\study\\_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    247\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    250\u001b[0m ):\n\u001b[1;32m--> 251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\demand\\lib\\site-packages\\optuna\\study\\_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 200\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    202\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    203\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn [44], line 20\u001b[0m, in \u001b[0;36mObjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m      7\u001b[0m lambda_sparse \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39msuggest_float(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlambda_sparse\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1e-6\u001b[39m, \u001b[38;5;241m1e-3\u001b[39m, log\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      8\u001b[0m tabnet_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(n_d\u001b[38;5;241m=\u001b[39mn_da, n_a\u001b[38;5;241m=\u001b[39mn_da, n_steps\u001b[38;5;241m=\u001b[39mn_steps, gamma\u001b[38;5;241m=\u001b[39mgamma,\n\u001b[0;32m      9\u001b[0m                  lambda_sparse\u001b[38;5;241m=\u001b[39mlambda_sparse, optimizer_fn\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam,\n\u001b[0;32m     10\u001b[0m                  optimizer_params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2e-2\u001b[39m, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     17\u001b[0m                  verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m     18\u001b[0m                  ) \u001b[38;5;66;03m#early stopping\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m kf \u001b[38;5;241m=\u001b[39m \u001b[43mKFold\u001b[49m(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     21\u001b[0m CV_score_array    \u001b[38;5;241m=\u001b[39m[]\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train_index, test_index \u001b[38;5;129;01min\u001b[39;00m kf\u001b[38;5;241m.\u001b[39msplit(X):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'KFold' is not defined"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\", study_name='TabNet optimization')\n",
    "study.optimize(Objective, timeout=6*60) #5 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fbdc05-93d1-4f08-95eb-68beb0c4f722",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
